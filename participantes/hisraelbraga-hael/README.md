# üì¶ rinha-2025-hael

API desenvolvida para a **Rinha de Backend 2025**, implementada na minha linguagem Hael, uma linguagem interpretada, cujo interpretador foi escrito em Go.

Meus mais sinceros agradecimentos ao Lucas Laurentino (3o colocado na Rinha) pelo artigo que ele fez sobre a sua participa√ß√£o na Rinha, explicando a sua abordagem e as tecnologias que usou. Eu pedi permiss√£o dele para copiar boa parte da sua estrat√©gia, para tornar poss√≠vel (e mais perform√°tica) a submiss√£o na minha linguagem Hael.
Dito isso, a maior parte do System Design, tecnologias e arquivos de configura√ß√£o eu me baseei na submiss√£o dele, fiz modifica√ß√µes para melhorar a performance e se adequar ao meu caso de uso, mas sem ele, talvez eu n√£o tivesse tido o mesmo sucesso nesse projeto. Obrigado!


##  Linguagem Hael

A Linguagem Hael possui um interpretador escrito em Go, ele possui um lexer (identifica e cria os tokens), um parser (cria objetos com os tokens e constr√≥i a Abstract Source Tree), e um evaluator (avalia os objetos e executa).

##  Arquitetura Geral

Para essa edi√ß√£o, o desafio era processar milhares de requisi√ß√µes de pagamentos, manter a consist√™ncia entre o payment processor e o processor da API, usando apenas 1,5 CPU e 350MB de RAM, al√©m de necessitar de pelo menos duas c√≥pias da API, tudo isso rodando em containeres Docker. Pra tornar isso poss√≠vel, era necess√°rio fazer uma aloca√ß√£o inteligente e distribuir bem os recursos para otimizar o m√°ximo poss√≠vel. 

Minha arquitetura final ficou com 2 inst√¢ncias da API, 1 Load Balancer Nginx, e 1 Banco de Dados PostgreSQL, como visto na figura a seguir:

![Arquitetura Geral](./arch.png)

##  Arquitetura Interna da API

Olhando a arquitetura interna da API, h√° 4 partes principais: 
- Request Handler: recebe a requisi√ß√£o, adiciona ela na fila, e retorna o mais r√°pido poss√≠vel
- Request Workers: retira itens da fila, processa eles, e adiciona no buffer para envio ao DB.
- Database Worker: faz o flush do buffer, fazendo o batch no DB. 
- Health Check Worker: verifica o estado da API, e envia o resultado para as outras c√≥pias do servi√ßo. 

A comunica√ß√£o entre r√©plicas √© feita atrav√©s do ZeroMQ, o servi√ßo Main executa o health-check, e faz o pub do melhor payment processor a ser usado, os outros servi√ßos fazem sub desse t√≥pico e atualizam de acordo com o andar dos testes. Para retirar o overhead do protocolo TCP, isolei o socket do ZeroMQ em um volume do Docker, e os servi√ßos se comunicam atrav√©s de IPC, um protocolo de comunica√ß√£o inter-processos, significativamente mais r√°pido. Essa √© uma estrat√©gia que foi utilizada tamb√©m para a comunica√ß√£o com o PostgreSQL, o socket foi isolado num volume para maior velocidade.

![Arquitetura Interna](./api-arch.png)

## Request Handler

O Request Handler √© o ponto de entrada da aplica√ß√£o, ele √© quem recebe as requisi√ß√µes. A ideia aqui √© que a resposta seja enviada o mais r√°pido poss√≠vel, e para isso, ao receber a requisi√ß√£o, o handler adiciona ela a uma queue de processamento, e em seguida j√° retorna uma resposta bem-sucedida.

## Request Workers

Os Request Workers s√£o os respons√°veis por processar a queue de pagamentos. A quantidade de workers pode ser alterada, mas na minha vers√£o final eu mantive 30 workers, foi o que me trouxe mais resultados. Cada worker desenfileira um item da queue (uma chan em Go, uma fila thread-safe), verifica o melhor processor para pagamento, envia para o payment processor e ent√£o, adiciona ele num buffer que posteriormente ser√° enviado para o Banco de dados.

## Database Worker

O Database Worker √© respons√°vel por fazer o batch de pagamentos para o banco de dados da aplica√ß√£o. √â um worker que a cada 1 segundo, esvazia o buffer de pagamentos e os envia para o banco de dados. Essa abordagem me permitiu reduzir (em muito) a quantidade de conex√µes necess√°rias para o banco de dados (j√° que s√≥ era utilizada uma por r√©plica da aplica√ß√£o) e tamb√©m reduzir os recursos necess√°rios para rodar o PostgreSQL, que agora recebia 2 requisi√ß√µes (apesar de com muitos dados) por segundo. Como mencionei no t√≥pico da Arquitetura, a comunica√ß√£o com o Postgres foi feita atrav√©s de um socket em um volume compartilhado com os servi√ßos da API.

## Health Check Workers

O Health Check Worker faz requisi√ß√µes a cada 5 segundos para o Payment Processor, verifica qual o melhor processador e atualiza o estado interno do servi√ßo, enquanto tamb√©m publica para as outras r√©plicas terem dados atualizados. Aqui h√° uma diferen√ßa entre as r√©plicas, para evitar que sejam feitas v√°rias requisi√ß√µes. Eu informo ao servi√ßo se ele √© o "main" atrav√©s de vari√°veis de ambiente. Somente o Main faz as requisi√ß√µes e publica, os outros d√£o sub no t√≥pico e apenas atualizam internamente. A comunica√ß√£o √© feita atrav√©s do socket ZeroMQ.

## Aloca√ß√£o de Recursos

Como eu falei no come√ßo, me baseei na submiss√£o do Lucas, ent√£o eu comecei seguindo a mesma aloca√ß√£o de recursos, por√©m eu estava tendo muuuuuitos problemas de performance, j√° que eu tenho um overhead de interpreta√ß√£o da minha linguagem. Dito isso, algumas modifica√ß√µes minhas tamb√©m permitiram reduzir cpu e mem√≥ria alocadas para o banco de dados, o que me deu mais performance para a aplica√ß√£o. Dito isso, o resultado final foi:
- 2 c√≥pias da aplica√ß√£o, cada uma com 0.5 CPU e 80MB de RAM.
- Servidor Nginx, com 0.2 CPU e 60MB de RAM.
- Inst√¢ncia do PostgreSQL, com 0.3 CPU e 130MB de RAM.

Totalizando assim os 350MB de RAM e 1.5 de CPU.

## üöÄ Como rodar

### Localmente
```sh
docker compose up -d --build
````

### Arquitetura ARM
```sh
docker compose -f docker-compose-arm64.yml up -d --build
````

